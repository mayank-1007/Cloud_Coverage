{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-06-21T21:55:20.992079Z",
     "iopub.status.busy": "2024-06-21T21:55:20.991625Z",
     "iopub.status.idle": "2024-06-21T21:55:20.999833Z",
     "shell.execute_reply": "2024-06-21T21:55:20.998837Z",
     "shell.execute_reply.started": "2024-06-21T21:55:20.992050Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import math\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense,Dropout,GRU,RNN,Conv1D,SimpleRNN, Bidirectional\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import optimizers, metrics, losses\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-21T21:55:22.079674Z",
     "iopub.status.busy": "2024-06-21T21:55:22.078873Z",
     "iopub.status.idle": "2024-06-21T21:55:24.526602Z",
     "shell.execute_reply": "2024-06-21T21:55:24.525574Z",
     "shell.execute_reply.started": "2024-06-21T21:55:22.079642Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-21T21:55:30.553264Z",
     "iopub.status.busy": "2024-06-21T21:55:30.552903Z",
     "iopub.status.idle": "2024-06-21T21:55:30.633380Z",
     "shell.execute_reply": "2024-06-21T21:55:30.632548Z",
     "shell.execute_reply.started": "2024-06-21T21:55:30.553238Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "# Get the index of the label column\n",
    "label_column = \"Total Cloud Cover [%]\"\n",
    "label_column_index = data.columns.get_loc(label_column)\n",
    "\n",
    "# Determine the split point (e.g., 80% training, 20% testing)\n",
    "split_point = int(len(data) * 0.9)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_data = data.iloc[:split_point]\n",
    "test_data = data.iloc[split_point:]\n",
    "\n",
    "train_data_scaled = scaler.fit_transform(train_data)\n",
    "test_data_scaled = scaler.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-21T21:55:31.052946Z",
     "iopub.status.busy": "2024-06-21T21:55:31.052511Z",
     "iopub.status.idle": "2024-06-21T21:55:31.078012Z",
     "shell.execute_reply": "2024-06-21T21:55:31.077003Z",
     "shell.execute_reply.started": "2024-06-21T21:55:31.052918Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Convert the DataFrames to NumPy arrays\n",
    "train_data_scaled = np.asarray(train_data_scaled).astype(np.float32)\n",
    "test_data_scaled = np.asarray(test_data_scaled).astype(np.float32)\n",
    "\n",
    "class TimeSeriesGenerator(tf.keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, data, look_back=75, step_ahead=30, batch_size=32, shuffle=True, target_column_index=-1):\n",
    "        'Initialization'\n",
    "        self.data = data\n",
    "        self.look_back = look_back\n",
    "        self.step_ahead = step_ahead\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.target_column_index = target_column_index\n",
    "        self.indices = np.arange(len(data) - look_back - step_ahead + 1)\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.indices) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        batch_indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(batch_indices)\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "\n",
    "    def __data_generation(self, batch_indices):\n",
    "        'Generates data containing batch_size samples'\n",
    "        X = np.empty((self.batch_size, self.look_back, self.data.shape[1]))\n",
    "        y = np.empty((self.batch_size,))\n",
    "        \n",
    "        for i, idx in enumerate(batch_indices):\n",
    "            X[i,] = self.data[idx:idx + self.look_back]\n",
    "            y[i,] = self.data[idx + self.look_back + self.step_ahead - 1, self.target_column_index]\n",
    "                \n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-21T21:55:31.750331Z",
     "iopub.status.busy": "2024-06-21T21:55:31.749957Z",
     "iopub.status.idle": "2024-06-21T21:55:31.756913Z",
     "shell.execute_reply": "2024-06-21T21:55:31.755776Z",
     "shell.execute_reply.started": "2024-06-21T21:55:31.750302Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def weighted_rmse(weights_zero, weights_nonzero):\n",
    "    def loss(y_true, y_pred):\n",
    "        # Create a mask for zero and non-zero values\n",
    "        is_zero = tf.cast(tf.equal(y_true, 0), tf.float32)\n",
    "        is_nonzero = 1 - is_zero\n",
    "        # Calculate squared error\n",
    "        sq_error = tf.square(y_true - y_pred)\n",
    "        \n",
    "        # Apply different weights to zero and non-zero errors\n",
    "        weighted_sq_error = (is_zero * weights_zero + is_nonzero * weights_nonzero) * sq_error\n",
    "        \n",
    "        # Calculate mean of weighted squared error and then take the square root\n",
    "        mean_weighted_sq_error = tf.reduce_mean(weighted_sq_error)\n",
    "        rmse = tf.sqrt(mean_weighted_sq_error)\n",
    "        return rmse\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-21T21:55:32.575767Z",
     "iopub.status.busy": "2024-06-21T21:55:32.574890Z",
     "iopub.status.idle": "2024-06-21T21:55:32.580476Z",
     "shell.execute_reply": "2024-06-21T21:55:32.579462Z",
     "shell.execute_reply.started": "2024-06-21T21:55:32.575735Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define configurations\n",
    "lstm_layer_configs =  [[100]]\n",
    "dense_layer_configs =  [[32,64]]\n",
    "configurations = [(lstm, dense) for lstm in lstm_layer_configs for dense in dense_layer_configs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-21T21:55:33.568912Z",
     "iopub.status.busy": "2024-06-21T21:55:33.568547Z",
     "iopub.status.idle": "2024-06-21T21:55:33.577240Z",
     "shell.execute_reply": "2024-06-21T21:55:33.576207Z",
     "shell.execute_reply.started": "2024-06-21T21:55:33.568885Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def build_model_bilstm(num_lstm_layers, lstm_units, num_dense_layers, dense_units, input_shape):\n",
    "    model = Sequential()\n",
    "    for i in range(num_lstm_layers):\n",
    "        if i == 0:\n",
    "            # First LSTM layer with input shape\n",
    "            model.add(Bidirectional(LSTM(lstm_units[i], return_sequences=(i < num_lstm_layers - 1), input_shape=input_shape)))\n",
    "            model.add(Dropout(0.2))\n",
    "        else:\n",
    "            model.add(Bidirectional(LSTM(lstm_units[i], return_sequences=(i < num_lstm_layers - 1))))\n",
    "\n",
    "    for i in range(num_dense_layers):\n",
    "        model.add(Dense(dense_units[i], activation='relu'))\n",
    "  \n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    model.compile(optimizer=Adam(), loss=weighted_rmse(weights_zero=0.2, weights_nonzero=0.8), metrics=[metrics.RootMeanSquaredError(), 'mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-21T21:55:34.110351Z",
     "iopub.status.busy": "2024-06-21T21:55:34.109724Z",
     "iopub.status.idle": "2024-06-21T21:55:34.118426Z",
     "shell.execute_reply": "2024-06-21T21:55:34.117415Z",
     "shell.execute_reply.started": "2024-06-21T21:55:34.110319Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def build_model_convlstm(num_lstm_layers, lstm_units, num_dense_layers, dense_units, input_shape):\n",
    "    model = Sequential()\n",
    "    # Add Conv1D layer\n",
    "    model.add(Conv1D(filters=32, kernel_size=5, activation='relu', input_shape=input_shape))\n",
    "    \n",
    "    for i in range(num_lstm_layers):\n",
    "        if i == 0:\n",
    "            # First LSTM layer with input shape\n",
    "            model.add(LSTM(lstm_units[i], return_sequences=(i < num_lstm_layers - 1)))\n",
    "            model.add(Dropout(0.2))\n",
    "        else:\n",
    "            model.add(LSTM(lstm_units[i], return_sequences=(i < num_lstm_layers - 1)))\n",
    "\n",
    "    for i in range(num_dense_layers):\n",
    "        model.add(Dense(dense_units[i], activation='relu'))\n",
    "  \n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    model.compile(optimizer=Adam(), loss=weighted_rmse(weights_zero=0.2, weights_nonzero=0.8), metrics=[metrics.RootMeanSquaredError(), 'mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-21T21:55:34.627708Z",
     "iopub.status.busy": "2024-06-21T21:55:34.626800Z",
     "iopub.status.idle": "2024-06-21T21:55:34.646489Z",
     "shell.execute_reply": "2024-06-21T21:55:34.645370Z",
     "shell.execute_reply.started": "2024-06-21T21:55:34.627669Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def run_model(model_type, lstm_units, dense_units, input_shape, train_gen, test_gen, horizon):\n",
    "    num_lstm_layers = len(lstm_units)\n",
    "    num_dense_layers = len(dense_units)\n",
    "    print(f\"Building model with {num_lstm_layers} {model_type.upper()} layers and {num_dense_layers} Dense layers for {horizon}-minute horizon\")\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    \n",
    "    if model_type == 'lstm':\n",
    "        model = build_model_lstm(num_lstm_layers, lstm_units, num_dense_layers, dense_units, input_shape)\n",
    "    elif model_type == 'rnn':\n",
    "        model = build_model_rnn(num_lstm_layers, lstm_units, num_dense_layers, dense_units, input_shape)\n",
    "    elif model_type == 'gru':\n",
    "        model = build_model_gru(num_lstm_layers, lstm_units, num_dense_layers, dense_units, input_shape)\n",
    "    elif model_type == 'bilstm':\n",
    "        model = build_model_bilstm(num_lstm_layers, lstm_units, num_dense_layers, dense_units, input_shape)\n",
    "    elif model_type == 'convlstm':\n",
    "        model = build_model_convlstm(num_lstm_layers, lstm_units, num_dense_layers, dense_units, input_shape)\n",
    "    \n",
    "    print(model.summary())\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(train_gen, epochs=10, validation_data=test_gen, callbacks=[early_stopping])\n",
    "\n",
    "    # Evaluate the model on the scaled test data\n",
    "    test_loss, test_rmse, test_mae = model.evaluate(test_gen)\n",
    "    print(f'Test Loss (scaled): {test_loss}, Test RMSE (scaled): {test_rmse}, Test MAE (scaled): {test_mae}')\n",
    "\n",
    "    # Make predictions on the test data with a progress bar\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    for i in tqdm(range(len(test_gen)), desc='Predicting', unit='batch'):\n",
    "        x_test, y_test = test_gen[i]\n",
    "        pred = model.predict(x_test, verbose=0)\n",
    "        predictions.append(pred)\n",
    "        true_labels.append(y_test)\n",
    "    \n",
    "    testPredict = np.concatenate(predictions).reshape(-1, 1)\n",
    "    testY = np.concatenate(true_labels).reshape(-1, 1)\n",
    "\n",
    "    # Repeat predictions to match the shape of the original data\n",
    "    testPredict_repeated = np.repeat(testPredict, 19, axis=-1)\n",
    "    testY_repeated = np.repeat(testY, 19, axis=-1)\n",
    "\n",
    "    # Inverse transform the repeated arrays\n",
    "    testPredict_original = scaler.inverse_transform(testPredict_repeated)[:, label_column_index]\n",
    "    testY_original = scaler.inverse_transform(testY_repeated)[:, label_column_index]\n",
    "\n",
    "    # Calculate evaluation metrics on the original scale\n",
    "    test_rmse_original = math.sqrt(mean_squared_error(testY_original, testPredict_original))\n",
    "    test_mae_original = mean_absolute_error(testY_original, testPredict_original)\n",
    "    test_r2_original = r2_score(testY_original, testPredict_original)\n",
    "    \n",
    "    print(f'Test RMSE (original scale): {test_rmse_original}')\n",
    "    print(f'Test MAE (original scale): {test_mae_original}')\n",
    "    print(f'Test R² (original scale): {test_r2_original}')\n",
    "\n",
    "    return history, test_loss, test_rmse_original, test_mae_original, test_r2_original, testY_original, testPredict_original\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-21T21:55:35.637079Z",
     "iopub.status.busy": "2024-06-21T21:55:35.636435Z",
     "iopub.status.idle": "2024-06-21T23:05:09.737271Z",
     "shell.execute_reply": "2024-06-21T23:05:09.735964Z",
     "shell.execute_reply.started": "2024-06-21T21:55:35.637045Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for 30-minute ahead prediction:\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m num_dense_layers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(dense_units)\n\u001b[0;32m     21\u001b[0m model \u001b[38;5;241m=\u001b[39m build_model_bilstm(num_lstm_layers, lstm_units, num_dense_layers, dense_units, input_shape)\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msummary\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     24\u001b[0m history, test_loss, test_rmse, test_mae, test_r2_original, testY_original, testPredict_original \u001b[38;5;241m=\u001b[39m run_model(model_type, lstm_units, dense_units, input_shape, train_gen, test_gen, horizon)\n\u001b[0;32m     25\u001b[0m models[horizon] \u001b[38;5;241m=\u001b[39m (history, test_loss, test_rmse, test_mae, test_r2_original)\n",
      "File \u001b[1;32mc:\\Users\\Mayank Manchanda\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\training.py:3214\u001b[0m, in \u001b[0;36mModel.summary\u001b[1;34m(self, line_length, positions, print_fn, expand_nested, show_trainable, layer_range)\u001b[0m\n\u001b[0;32m   3184\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Prints a string summary of the network.\u001b[39;00m\n\u001b[0;32m   3185\u001b[0m \n\u001b[0;32m   3186\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3211\u001b[0m \u001b[38;5;124;03m    ValueError: if `summary()` is called before the model is built.\u001b[39;00m\n\u001b[0;32m   3212\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilt:\n\u001b[1;32m-> 3214\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   3215\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis model has not yet been built. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3216\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBuild the model first by calling `build()` or by calling \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3217\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe model on a batch of data.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3218\u001b[0m     )\n\u001b[0;32m   3219\u001b[0m layer_utils\u001b[38;5;241m.\u001b[39mprint_summary(\n\u001b[0;32m   3220\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   3221\u001b[0m     line_length\u001b[38;5;241m=\u001b[39mline_length,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3226\u001b[0m     layer_range\u001b[38;5;241m=\u001b[39mlayer_range,\n\u001b[0;32m   3227\u001b[0m )\n",
      "\u001b[1;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data."
     ]
    }
   ],
   "source": [
    "forecast_horizons = [30, 25, 15] \n",
    "models = {}\n",
    "weights = {15: 0.5, 25: 0.35, 30: 0.15}\n",
    "model_type = 'bilstm'\n",
    "\n",
    "all_predictions = {}\n",
    "all_true_values = {}\n",
    "\n",
    "for horizon in forecast_horizons:\n",
    "    print(f\"Training model for {horizon}-minute ahead prediction:\")\n",
    "    # Create generators for each horizon\n",
    "    train_gen = TimeSeriesGenerator(train_data_scaled, step_ahead=horizon, batch_size=32, shuffle=True, target_column_index=6)\n",
    "    test_gen = TimeSeriesGenerator(test_data_scaled, step_ahead=horizon, batch_size=32, shuffle=False, target_column_index=6)\n",
    "    input_shape = (train_gen.look_back, train_data_scaled.shape[1])\n",
    "    \n",
    "    config_index = 0  # Adjust this index to run different configurations\n",
    "    lstm_units, dense_units = configurations[config_index]\n",
    "    num_lstm_layers = len(lstm_units)\n",
    "    num_dense_layers = len(dense_units)\n",
    "\n",
    "    model = build_model_bilstm(num_lstm_layers, lstm_units, num_dense_layers, dense_units, input_shape)\n",
    "    print(model.summary())\n",
    "    \n",
    "    history, test_loss, test_rmse, test_mae, test_r2_original, testY_original, testPredict_original = run_model(model_type, lstm_units, dense_units, input_shape, train_gen, test_gen, horizon)\n",
    "    models[horizon] = (history, test_loss, test_rmse, test_mae, test_r2_original)\n",
    "    \n",
    "    all_true_values[horizon] = testY_original\n",
    "    all_predictions[horizon] = testPredict_original\n",
    "\n",
    "weighted_sum = sum(weights[horizon] * models[horizon][4] for horizon in forecast_horizons)\n",
    "print(f\"Weighted Sum of R² Scores: {weighted_sum}\")\n",
    "\n",
    "# Plotting all horizons on a single graph\n",
    "fig = go.Figure()\n",
    "\n",
    "for horizon in forecast_horizons:\n",
    "    fig.add_trace(go.Scatter(x=list(range(len(all_true_values[horizon]))), y=all_true_values[horizon], mode='lines', name=f'True Values {horizon}-min'))\n",
    "    fig.add_trace(go.Scatter(x=list(range(len(all_predictions[horizon]))), y=all_predictions[horizon], mode='lines', name=f'Predicted Values {horizon}-min'))\n",
    "\n",
    "fig.update_layout(title='True vs Predicted Values for All Horizons', xaxis_title='Index', yaxis_title='Value', template='plotly_dark')\n",
    "\n",
    "# Save the interactive plot as an HTML file\n",
    "filename = \"forecast_all_horizons_bilstm.html\"\n",
    "fig.write_html(filename)\n",
    "print(f\"Interactive plot saved as {filename}\")\n",
    "\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-21T23:14:06.353458Z",
     "iopub.status.busy": "2024-06-21T23:14:06.352492Z",
     "iopub.status.idle": "2024-06-21T23:56:31.863031Z",
     "shell.execute_reply": "2024-06-21T23:56:31.861438Z",
     "shell.execute_reply.started": "2024-06-21T23:14:06.353410Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for 30-minute ahead prediction:\n",
      "Building model with 1 CONVLSTM layers and 2 Dense layers for 30-minute horizon\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 71, 32)            3072      \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 100)               53200     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 32)                3232      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                2112      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 61,681\n",
      "Trainable params: 61,681\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "forecast_horizons = [30, 25, 15] \n",
    "models = {}\n",
    "weights = {15: 0.5, 25: 0.35, 30: 0.15}\n",
    "model_type = 'convlstm'\n",
    "\n",
    "all_predictions = {}\n",
    "all_true_values = {}\n",
    "\n",
    "for horizon in forecast_horizons:\n",
    "    print(f\"Training model for {horizon}-minute ahead prediction:\")\n",
    "    # Create generators for each horizon\n",
    "    train_gen = TimeSeriesGenerator(train_data_scaled, step_ahead=horizon, batch_size=32, shuffle=True, target_column_index=6)\n",
    "    test_gen = TimeSeriesGenerator(test_data_scaled, step_ahead=horizon, batch_size=32, shuffle=False, target_column_index=6)\n",
    "    input_shape = (train_gen.look_back, train_data_scaled.shape[1])\n",
    "    \n",
    "    config_index = 0  # Adjust this index to run different configurations\n",
    "    lstm_units, dense_units = configurations[config_index]\n",
    "    \n",
    "    history, test_loss, test_rmse, test_mae, test_r2_original, testY_original, testPredict_original = run_model(model_type, lstm_units, dense_units, input_shape, train_gen, test_gen, horizon)\n",
    "    models[horizon] = (history, test_loss, test_rmse, test_mae, test_r2_original)\n",
    "    \n",
    "    all_true_values[horizon] = testY_original\n",
    "    all_predictions[horizon] = testPredict_original\n",
    "\n",
    "weighted_sum = sum(weights[horizon] * models[horizon][4] for horizon in forecast_horizons)\n",
    "print(f\"Weighted Sum of R² Scores: {weighted_sum}\")\n",
    "\n",
    "# Plotting all horizons on a single graph\n",
    "fig = go.Figure()\n",
    "\n",
    "for horizon in forecast_horizons:\n",
    "    fig.add_trace(go.Scatter(x=list(range(len(all_true_values[horizon]))), y=all_true_values[horizon], mode='lines', name=f'True Values {horizon}-min'))\n",
    "    fig.add_trace(go.Scatter(x=list(range(len(all_predictions[horizon]))), y=all_predictions[horizon], mode='lines', name=f'Predicted Values {horizon}-min'))\n",
    "\n",
    "fig.update_layout(title='True vs Predicted Values for All Horizons', xaxis_title='Index', yaxis_title='Value', template='plotly_dark')\n",
    "\n",
    "# Save the interactive plot as an HTML file\n",
    "filename = \"forecast_all_horizons_convlstm.html\"\n",
    "fig.write_html(filename)\n",
    "print(f\"Interactive plot saved as {filename}\")\n",
    "\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 5255845,
     "sourceId": 8750591,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30733,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
